{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Blog Word Cloud Generator 📝☁️\n",
    "\n",
    "Blogger、はてなブログ、note、アメーバブログなど、さまざまなブログの記事を分析してワードクラウドを生成します。\n",
    "\n",
    "分析したいブログのURL、基準日、遡る日数を入力して、下の▶ボタンを押してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "forms": {
      " বিবিধ ": false,
      "সাইজ ": 1,
      "সময়ের বিন্যাস": false,
      "입력란": true
     }
    }
   },
   "outputs": [],
   "source": [
    "#@title ◆ 設定と実行 ◆\n",
    "#@markdown --- \n",
    "#@markdown ### 1. 分析したいブログの情報を入力\n",
    "#@markdown **分析したいブログのURLを入力してください**\n",
    "blog_url = \"\" #@param {type:\"string\"}\n",
    "#@markdown \n",
    "#@markdown --- \n",
    "#@markdown ### 2. 分析する期間を指定\n",
    "#@markdown **基準日（この日まで）を指定してください。空欄の場合は今日になります。**\n",
    "base_date_str = \"\" #@param {type:\"date\"}\n",
    "#@markdown **基準日から何日遡って分析するか指定してください。**\n",
    "days_to_go_back = 30 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
    "\n",
    "#@markdown --- \n",
    "#@markdown **設定が終わったら、このセルを実行してください（左の▶ボタンをクリック）**\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from janome.tokenizer import Tokenizer\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from urllib.parse import urljoin\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "\n",
    "if not blog_url:\n",
    "    raise ValueError(\"ブログのURLが入力されていません。入力してから再度実行してください。\")\n",
    "\n",
    "# --- 日付のデフォルト値を設定 ---\n",
    "jst = timezone(timedelta(hours=9))\n",
    "today = datetime.now(jst)\n",
    "if base_date_str:\n",
    "    end_date_obj = datetime.strptime(base_date_str, '%Y-%m-%d').replace(hour=23, minute=59, second=59, tzinfo=jst)\n",
    "else:\n",
    "    end_date_obj = today\n",
    "start_date_obj = end_date_obj - timedelta(days=days_to_go_back)\n",
    "\n",
    "# --- 環境準備 ---\n",
    "print(\"環境の準備中です...\")\n",
    "print(\"1. 必要なライブラリをインストールしています。\")\n",
    "!pip install requests beautifulsoup4 janome wordcloud matplotlib > /dev/null 2>&1\n",
    "print(\"2. 日本語フォントをダウンロードしています。\")\n",
    "font_path = '/content/NotoSansCJKjp-Regular.otf'\n",
    "if not os.path.exists(font_path) or os.path.getsize(font_path) < 1024*1024:\n",
    "    !wget -q -O {font_path} https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/Japanese/NotoSansCJKjp-Regular.otf\n",
    "\n",
    "print(\"3. GitHubから除外ワードリスト(stopwords.txt)を取得しています。\")\n",
    "github_repo_url = \"https://github.com/amufaamo/blog-to-tagcloud\"\n",
    "stopwords_url = github_repo_url.replace('github.com', 'raw.githubusercontent.com') + '/main/stopwords.txt'\n",
    "!wget -q -O /content/stopwords.txt {stopwords_url}\n",
    "\n",
    "print(\"準備が完了しました！\\n\")\n",
    "\n",
    "# --- ▼▼▼ ここからが新しい分析エンジン ▼▼▼ ---\n",
    "PLATFORM_CONFIGS = {\n",
    "    'blogger': {\n",
    "        'post_container': 'article.post-outer-container',\n",
    "        'permalink': 'h3.post-title a',\n",
    "        'date': 'time.published',\n",
    "        'date_attribute': 'datetime',\n",
    "        'content_body': 'div.post-body',\n",
    "        'pagination': 'a.blog-pager-older-link',\n",
    "    },\n",
    "    'hatenablog': {\n",
    "        'post_container': 'article.entry',\n",
    "        'permalink': 'h1.entry-title a',\n",
    "        'date': 'time[datetime]',\n",
    "        'date_attribute': 'datetime',\n",
    "        'content_body': 'div.entry-content',\n",
    "        'pagination': 'a[rel=\"next\"]',\n",
    "    },\n",
    "    'ameblo': {\n",
    "        'post_container': 'li[data-unique-entry-id]',\n",
    "        'permalink': 'a[data-gtm-user-entry-title]',\n",
    "        'date': 'time',\n",
    "        'date_attribute': 'datetime',\n",
    "        'content_body': 'div[data-unique-entry-body]',\n",
    "        'pagination': 'a[data-gtm-button-name=\"記事一覧_次へ\"]',\n",
    "    },\n",
    "    'note': {\n",
    "        'post_container': 'div.o-cardNote',\n",
    "        'permalink': 'a.o-cardNote__link',\n",
    "        'date': 'time',\n",
    "        'date_attribute': 'datetime',\n",
    "        'content_body': 'div.note-common-styles__p',\n",
    "        'pagination': None, # 無限スクロールのため\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_platform(url):\n",
    "    if 'hatenablog' in url: return 'hatenablog'\n",
    "    if 'ameblo.jp' in url: return 'ameblo'\n",
    "    if 'note.com' in url: return 'note'\n",
    "    if 'blogspot.com' in url: return 'blogger'\n",
    "    return None\n",
    "\n",
    "def load_stopwords(filepath='/content/stopwords.txt'):\n",
    "    if not os.path.exists(filepath): return set()\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        stopwords = {line.strip() for line in f if line.strip()}\n",
    "    print(f\"{len(stopwords)}個の除外ワードを読み込みました。\")\n",
    "    return stopwords\n",
    "\n",
    "def analyze_blog(base_url, start_date, end_date, stopwords):\n",
    "    platform = detect_platform(base_url)\n",
    "    if not platform:\n",
    "        print(\"エラー: 対応していないブログプラットフォームです。 (Blogger, はてな, note, アメブロに対応)\")\n",
    "        return None\n",
    "    print(f\"プラットフォーム: {platform.capitalize()} を検出しました。\")\n",
    "    config = PLATFORM_CONFIGS[platform]\n",
    "    \n",
    "    all_text = \"\"\n",
    "    current_url = base_url\n",
    "    page_num = 1\n",
    "    \n",
    "    print(f\"ブログの分析を開始します。対象期間: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    while current_url:\n",
    "        print(f\"記事一覧ページ {page_num} を取得中: {current_url}\")\n",
    "        try:\n",
    "            response = requests.get(current_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.encoding = 'utf-8'\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            time.sleep(1) # サーバーに優しく\n",
    "        except:\n",
    "            print(\"エラー: ページにアクセスできませんでした。\")\n",
    "            break\n",
    "        \n",
    "        posts = soup.select(config['post_container'])\n",
    "        if not posts: \n",
    "            print(\"記事が見つかりませんでした。クロールを終了します。\")\n",
    "            break\n",
    "\n",
    "        stop_crawling = False\n",
    "        for post in posts:\n",
    "            date_tag = post.select_one(config['date'])\n",
    "            link_tag = post.select_one(config['permalink'])\n",
    "            \n",
    "            if not date_tag or not link_tag:\n",
    "                continue\n",
    "\n",
    "            post_date_str = date_tag.get(config['date_attribute'])\n",
    "            if not post_date_str: continue\n",
    "            \n",
    "            try:\n",
    "                post_date = datetime.fromisoformat(post_date_str.replace('Z', '+00:00'))\n",
    "            except ValueError:\n",
    "                continue # 日付形式が不正な場合はスキップ\n",
    "            \n",
    "            if start_date <= post_date <= end_date:\n",
    "                post_url = urljoin(base_url, link_tag['href'])\n",
    "                print(f\"  -> 期間内の記事を発見({post_date.strftime('%Y-%m-%d')})、内容を取得中: {post_url}\")\n",
    "                try:\n",
    "                    post_res = requests.get(post_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                    post_res.encoding = 'utf-8'\n",
    "                    post_soup = BeautifulSoup(post_res.text, 'html.parser')\n",
    "                    content_body = post_soup.select_one(config['content_body'])\n",
    "                    if content_body:\n",
    "                        all_text += content_body.get_text() + \"\\n\"\n",
    "                    time.sleep(1) # サーバーに優しく\n",
    "                except:\n",
    "                    print(f\"     -> 記事ページの取得に失敗しました。\")\n",
    "\n",
    "            elif post_date < start_date:\n",
    "                stop_crawling = True\n",
    "                break\n",
    "        \n",
    "        if stop_crawling:\n",
    "            print(\"対象期間外の記事に到達したため、クロールを終了します。\")\n",
    "            break\n",
    "        \n",
    "        if config['pagination']:\n",
    "            next_page_tag = soup.select_one(config['pagination'])\n",
    "            if next_page_tag and next_page_tag.has_attr('href'):\n",
    "                current_url = urljoin(base_url, next_page_tag['href'])\n",
    "                page_num += 1\n",
    "            else:\n",
    "                current_url = None\n",
    "        else: # note.comなどページネーションがない場合\n",
    "            print(f\"{platform.capitalize()}は複数ページのクロールに非対応のため、最初のページのみ分析します。\")\n",
    "            current_url = None\n",
    "\n",
    "    if not all_text: return None\n",
    "    print(\"\\nテキストの解析中...\")\n",
    "    t = Tokenizer()\n",
    "    words = [token.surface for token in t.tokenize(all_text) \n",
    "             if token.surface not in stopwords and \n",
    "             token.part_of_speech.startswith(('名詞', '動詞', '形容詞')) and \n",
    "             len(token.surface) > 1 and not re.match(r'^[0-9a-zA-Z]+$', token.surface)]\n",
    "    return Counter(words)\n",
    "\n",
    "# メイン処理\n",
    "custom_stopwords = load_stopwords()\n",
    "word_counter = analyze_blog(blog_url, start_date_obj, end_date_obj, custom_stopwords)\n",
    "\n",
    "if word_counter:\n",
    "    print(\"\\n--- ✅単語の頻度ランキング TOP 50 ---\")\n",
    "    for word, count in word_counter.most_common(50):\n",
    "        print(f\"{word}: {count}回\")\n",
    "    print(\"\\nワードクラウド画像を生成中...\")\n",
    "    if os.path.exists(font_path) and os.path.getsize(font_path) > 1000000:\n",
    "      try:\n",
    "        wordcloud = WordCloud(width=1200, height=600, background_color='white', font_path=font_path, max_words=150, colormap='viridis').generate_from_frequencies(word_counter)\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "      except OSError as e:\n",
    "        print(f\"\\nエラー: ワードクラウドの生成中にエラーが発生しました。\")\n",
    "    else:\n",
    "        print(f\"エラー：フォントファイルが正しくダウンロードできませんでした。「ランタイムの再起動」を試してください。\")\n",
    "else:\n",
    "    print(\"エラー: 分析対象の記事が見つかりませんでした。URLや期間を確認してください。\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
